---
title: "Group 7 - Classification model for the default status"
author: "L. Becker, A. Chebatarova, A. Kandel, A.Kusche, R. Mizrak"
date: 'Sys.Date()'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Initialization

```{r initialization, results="hide"}
source(file = "functions.R")
func_init_env()
```

```{r loading Rds file, results="hide"}
dataset <- func_data_load()
```

```{r preprocessing, echo=TRUE}
dataset <- func_data_prep(dataset)
```

# Preparatory tasks

```{r, results= FALSE}
# Make a data.table
setDT(dataset)

# filter out all observations with loan_status == Current
dataset <- dataset[loan_status != 'Current']

# Change all the loan status that are not "Fully Paid" to 1 = "Default"
dataset$defaulted[dataset$loan_status != "Fully Paid"] <- 1

# Chaning levels of defaulted to have "Default" and "Paying"
levels(dataset$defaulted) = c(1, 0)

# Change all the defaulted values that aren't "Default" to 0
dataset$defaulted[is.na(dataset$defaulted)] <- 0

# remove dependent variable, because now defaulted exists
dataset$loan_status <- NULL

# set defaulted as factor
dataset$defaulted <- as.factor(dataset$defaulted)

#show defaulted vs non defaulted
table(dataset$defaulted)

# # Removing Feature 
# dataset <- subset(dataset, select = -c(hardship_type, hardship_status, hardship_loan_status,settlement_status, verification_status_joint, hardship_flag, disbursement_method, debt_settlement_flag, application_type, purpose, pymnt_plan, verification_status, home_ownership, initial_list_status, term))
```

```{r}
#dataset <- dummy.data.frame(dataset, names = c("application_type","debt_settlement_flag", "disbursement_method","hardship_flag","hardship_loan_status","hardship_type","home_ownership","initial_list_status","purpose","term", "settlement_status"))

#dataset <- dummy.data.frame(dataset, names = c("hardship_reason", "hardship_status","pymnt_plan", "settlement_status", "verification_status", "verification_status_joint"))
```

## Create Train and Testset

```{r validation set approach}
# setting a seed for reproducability
set.seed(7)

# random split into  train and test set, with a ratio of 20:80
trainIndex <- sample(1:nrow(dataset),0.8*nrow(dataset))

train.data <- dataset[trainIndex,]
test.data  <- dataset[-trainIndex,]

# creating a small subset of data for testing models
train_smallIndex  <- sample(1:nrow(train.data), 1000)
test_smallIndex   <- sample(1:nrow(test.data), 1000)

small_train <- dataset[train_smallIndex,]
small_test  <- dataset[test_smallIndex,]

train.data <- small_train
test.data  <- small_test
```

```{r}
# Compile cross-validation settings
set.seed(100)
myfolds <- createMultiFolds(train.data, k = 5, times = 10)
control <- trainControl("repeatedcv", index = myfolds, selectionFunction = "oneSE")
 
```


# Main tasks:
## Use Principal Component Analysis for base transformation and then compare it with the Partial Least Squares Regression result. Select the best base with cross validation, using the better of the two approaches.

##Perform Partial Least Squares Regression
```{r}

# Train PLS model
mod1 <- train(defaulted ~ ., data = train.data,
 method = "pls",
 metric = "Accuracy",
 tuneLength = 20,
 trControl = control,
 preProc = c("zv","center","scale"))

plot(mod1)

```

##Perform Principal Component Analysis 
```{r}
# PCA-DA
mod2 <- train(defaulted ~ ., data = train.data,
method = "lda",
metric = "Accuracy",
trControl = control,
preProc = c("zv","center","scale","pca"))
```

## Compile models and compare performance
```{r, message=FALSE, warning=FALSE, results="hide"}

models <- resamples(list("PLS-DA" = mod1, "PCA-DA" = mod2))
bwplot(models, metric = "Accuracy")

plot(varImp(mod1), mod1$bestTune$ncomp, main = "PLS-DA")
#plot(varImp(mod2), 5, main = "PCA-DA")

```
```{r eval=FALSE, results="hide"}
#Limit dataset to relevant variables from PLS
total_rec_prncp, recoveries, collection_recovery_fee, last_pymnt_amnt, total_pymnt_inv, total_pymnt, debt_settlement_flag, sub_grade, int_rate, out_prncp, out_prncp_inv, settlement_status, term

train.data <- subset(train.data, select = c(defaulted, total_rec_prncp, recoveries, collection_recovery_fee, last_pymnt_amnt, total_pymnt_inv, total_pymnt, debt_settlement_flag, sub_grade, int_rate, out_prncp, out_prncp_inv, settlement_status, term))
test.data  <- subset(test.data, select = c(defaulted, total_rec_prncp, recoveries, collection_recovery_fee, last_pymnt_amnt, total_pymnt_inv, total_pymnt, debt_settlement_flag, sub_grade, int_rate, out_prncp, out_prncp_inv, settlement_status, term))
```

## Perform the classification using KNN, Logistic Regression, Decision tree and Random forest.

```{r Perform KNN with caret, include=FALSE}

fit.knn  <- train(defaulted ~ ., 
                data = train.data, 
                method = "knn",
                trControl = control,
                preProc = c("zv","center","scale")
                ) 

```

```{r Perform Logistic Regression with caret, include=FALSE}
## Logistic regression
fit.lreg <-train(defaulted ~ recoveries + collection_recovery_fee + total_rec_prncp + last_pymnt_amnt + total_pymnt, 
                data = train.data, 
                method = "glm",
                trControl = control,
                family=binomial(),
                preProc = c("zv","center","scale")
                ) 

```

```{r Perform Decision tree with caret, include=FALSE}
## decision tree 
fit.dtree<-train(defaulted ~ recoveries + collection_recovery_fee + total_rec_prncp + last_pymnt_amnt + total_pymnt, 
               data=train.data,
               method="ctree",
               trControl = control,
               preProc = c("zv","center","scale"))
```

```{r Perform Random Forest with caret, include=FALSE}
## random forest 
fit.rf<-train(defaulted ~ recoveries + collection_recovery_fee + total_rec_prncp + last_pymnt_amnt + total_pymnt, 
               data=train.data,
               method="rf",
               trControl = control,
               preProc = c("zv","center","scale"))
```

## Perform the prediction on the validation set and compute the confusion matrix.

```{r Perform Confusion Matrix for each method, include=FALSE}

#Confusion Matrix KNN
confusionMatrix( predict(fit.knn), train.data$defaulted)              #Train
confusionMatrix( predict(fit.knn, test.data), test.data$defaulted)    #Test

#Confusion Matrix Logistic Regression
confusionMatrix( predict(fit.lreg), train.data$defaulted)             #Train
confusionMatrix( predict(fit.lreg, test.data), test.data$defaulted)   #Test

#Confusion Matrix Decision Trees
confusionMatrix( predict(fit.dtree), train.data$defaulted)            #Train
confusionMatrix( predict(fit.dtree, test.data), test.data$defaulted)  #Test

#Confusion Matrix Random Forest
confusionMatrix( predict(fit.rf), train.data$defaulted)               #Train
confusionMatrix( predict(fit.rf, test.data), test.data$defaulted)     #Test
```

## Compare the respective train and test error performances to select one of these approaches.

```{r ROC Plot}
par(pty = "s")
roc(test.data$defaulted, as.numeric(predict(fit.dtree, test.data)), plot=TRUE, legacy.axes=TRUE, percent=TRUE, xlab="False Positive Percentage", ylab="True Postive Percentage", col="#377eb8", lwd=4, print.auc = TRUE, print.auc.y=80, print.auc.x=30)

plot.roc(test.data$defaulted, as.numeric(predict(fit.rf, test.data)), percent=TRUE, col="#b8377e", lwd=4, print.auc=TRUE, add=TRUE, print.auc.y=70, print.auc.x=30)

plot.roc(test.data$defaulted, as.numeric(predict(fit.dtree, test.data)), percent=TRUE, col="#b87137", lwd=4, print.auc=TRUE, add=TRUE, print.auc.y=60, print.auc.x=30)

plot.roc(test.data$defaulted, as.numeric(predict(fit.knn, test.data)), percent=TRUE, col="#7eb837", lwd=4, print.auc=TRUE, add=TRUE, print.auc.y=50, print.auc.x=30)

legend("bottomright", legend=c("Decission Tree", "Random Forest", "Logisitic Regression", "KNN"), col=c("#377eb8", "#b8377e", "#b87137", "#7eb837"), lwd=4)
```
 
## Conceptually compare your approach with a solution existing for this problem. (Default
prediction is a very well-known problem in literature).
```{r }

```
