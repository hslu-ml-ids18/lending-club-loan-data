---
title: "Group 7 - Classification model for the default status"
author: "L. Becker, A. Chebatarova, A. Kandel, A.Kusche, R. Mizrak"
date: 'Sys.Date()'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

## Initialization

```{r initialization, message=FALSE, warning=FALSE, results="hide"}
source(file = "functions.R")
func_init_env()
```

```{r loading Rds file, results="hide"}
dataset <- func_data_load()
```

```{r preprocessing, echo=TRUE}
dataset <- func_data_prep(dataset)
```


```{r concluded loans}
# filter out all observations with loan_status == Current
# Change all the loan status that are not "Fully Paid" to "Default"
setDT(dataset)
dataset <- dataset[loan_status != 'Current']
dataset$loan_status[dataset$loan_status != "Fully Paid"] <- "Default"
```

```{r validation set approach}
# setting a seed for reproducability
set.seed(7)

# random split into  train and test set, with a ratio of 20:80
trainIndex <- sample(1:nrow(dataset),0.01*nrow(dataset))

train.data <- dataset[trainIndex]
test.data  <- dataset[-trainIndex]

```

Use Principal Component Analysis for base transformation and then compare it with the Partial Least Squares Regression result. Select the best base with cross validation, using the better of the two approaches. 
-> http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/152-principal-component-and-partial-least-squares-regression-essentials/
-> https://www.datacamp.com/community/tutorials/pca-analysis-r
```{r }
# convert categorical variables into numeric                   
tds <- data.frame(model.matrix( ~ .- 1, data=dataset)) 
tds
str(tds)

# pcr like in the slides
#attach(dataset)
#pcr.fit= pcr(loan_status ~ ., data=tds ,scale=FALSE ,
#validation ="CV")


#other way convert categorical variables into numeric 
#library(dummies)
#new_my_data <- dummy.data.frame(dataset, names = c("term","home_ownership"))
#str(new_my_data)



train.pca <- prcomp(train.data, center = TRUE,scale. = TRUE)

summary(train.pca)

# Build the model on training set

model <- train(
  loan_status~., data = train.data, method = "pcr",
  scale = TRUE,
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
# Plot model RMSE vs different values of components
plot(model)
# Print the best tuning parameter ncomp that
# minimize the cross-validation error, RMSE
model$bestTune


```

Perform the classification using KNN.
```{r }

```
Perform the classification using Logistic Regression.
```{r }

```
Perform the classification using Decision tree.
```{r }

```
Perform the classification using Random forest.
```{r }

```
Compare the respective train and test error performances to select one of these approaches.
```{r }

```

Perform the prediction on the validation set and compute the confusion matrix.
```{r }

```

Conceptually compare your approach with a solution existing for this problem. (Default
prediction is a very well-known problem in literature).
```{r }

```
