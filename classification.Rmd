---
title: "Group 7 - Classification model for the default status"
author: "L. Becker, A. Chebatarova, A. Kandel, A.Kusche, R. Mizrak"
date: 'Sys.Date()'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

## Initialization

```{r initialization, message=FALSE, warning=FALSE, results="hide"}
source(file = "functions.R")
func_init_env()
```

```{r loading Rds file, results="hide"}
dataset <- func_data_load()
```

```{r preprocessing, echo=TRUE}
dataset <- func_data_prep(dataset)
```


```{r concluded loans results= FALSE}
# filter out all observations with loan_status == Current & check loan_status
as.data.table(dataset)
# dataset <- dataset[loan_status != 'Current']
dataset$loan_status[dataset$loan_status != "Fully Paid"] <- "Default"
```
```{r  create a "defaulted" column for classification}
# We create a new column, "defaulted" which has value 1 if the credit was defaulted.
# the column has value 0 if it hasne't defaulted.
levels_loan_status <- as.vector(levels(dataset$loan_status))
dataset$defaulted <- mapvalues(dataset$loan_status, levels_loan_status, c(0,0,1,0,0,0,0,0,0))
```


```{r validation set approach}
dataset$defaulted <- as.numeric(dataset$defaulted)
dataset <- subset(dataset, select = -c(hardship_type, hardship_reason, hardship_status, hardship_loan_status,settlement_status, verification_status_joint, hardship_flag, disbursement_method, debt_settlement_flag, application_type, purpose, pymnt_plan, loan_status, verification_status, home_ownership, initial_list_status, term))
# setting a seed for reproducability
set.seed(7)

# random split into  train and test set, with a ratio of 20:80
trainIndex <- sample(1:nrow(dataset),0.01*nrow(dataset))

train.data <- dataset[trainIndex,]
test.data  <- dataset[-trainIndex,]
# creating a small subset of rows testing models

small_trainRows = sample(1:nrow(dataset),0.004*nrow(dataset))
small_testRows = sample(nrow(dataset) - small_trainRows,0.004*nrow(dataset))

# creating a small subset of data for testing models
small_train <- dataset[small_trainRows,]
small_test <- dataset[small_testRows,]
```

Use Principal Component Analysis for base transformation and then compare it with the Partial Least Squares Regression result. Select the best base with cross validation, using the better of the two approaches. 
-> http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/152-principal-component-and-partial-least-squares-regression-essentials/
-> https://www.datacamp.com/community/tutorials/pca-analysis-r
```{r }
train.pca <- prcomp(train.data[,c(1,2,3,4)], center = TRUE,scale. = TRUE)

summary(train.pca)

# Build the model on training set

model <- train(
  loan_status~., data = train.data, method = "pcr",
  scale = TRUE,
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
# Plot model RMSE vs different values of components
plot(model)
# Print the best tuning parameter ncomp that
# minimize the cross-validation error, RMSE
model$bestTune


```

Perform the classification using KNN.
```{r k-NN}
# Set random seed.
set.seed(7)

# Creating test and train labels
train_labels <- small_train$defaulted
test_labels <- small_test$defaulted

# 
knn_train <- small_train
knn_test <- small_test

# droping defaulted columns
knn_train$defaulted <- NULL
knn_test$defaulted <- NULL

# Make predictions using knn: pred
pred <- knn(train = knn_train, test = knn_test, cl = train_labels, k = 5)

# Construct the confusion matrix: conf
conf <- table(test_labels, pred)

# Print out the confusion matrix
conf

# Define range and accs
range <- 1:round(0.2 * nrow(knn_train))
accs <- rep(0, length(range))
for (k in range) {

  # Make predictions using knn: pred
  pred <- knn(knn_train, knn_test, train_labels, k = k)

  # Construct the confusion matrix: conf
  conf <- table(test_labels, pred)

  # Clculate the accuracy and store it in accs[k]
  accs[k] <- sum(diag(conf)) / sum(conf)
}
# Plot the accuracies. Title of x-axis is "k".
plot(range, accs, xlab = "k")

# Calculate the best k
which.max(accs)

```

Compare the respective train and test error performances to select one of these approaches.
```{r }

```

Perform the prediction on the validation set and compute the confusion matrix.
```{r }

```

Conceptually compare your approach with a solution existing for this problem. (Default
prediction is a very well-known problem in literature).
```{r }

```
