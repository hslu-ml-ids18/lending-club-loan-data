---
title: "Data_Preparation"
author: "L. Becker, A. Chebatarova, A. Kandel, A.Kusche, R. Mizrak"
date: "5/13/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Data Loading}
# we load the loan file and select lineitems that fit our group number 7
# we might move this somewhere else and use only the prepared csv as this is time consuming

loan_df <- read.csv(file = "loan.csv", header = TRUE)
loan_df <- cbind(id_2 = rownames(loan_df), loan_df)
rownames(loan_df) <- 1:nrow(loan_df)
loan_df$id_2 <- as.numeric(loan_df$id_2)
dataset_7 <- loan_df[which(loan_df$id_2%%8+1== 7),]
```

```{r Saving dataset as rds}
# Write RDS in R

saveRDS(dataset_7, file = "dataset_7.Rds")
```

```{r loading Rds file}
dataset_7 <- readRDS("dataset_7.Rds")
```

<!-- ```{r exception to removing NAs colums} -->
<!-- # total_rec_late_fee woould be removed because it has mostly NA's but I believe we should keep that one an dummy code it to 0 as it could be usefull for defaulting  -->
<!-- summary(dataset_7$total_rec_late_fee) -->
<!-- summary(dataset_7$recoveries) -->
<!-- typeof(dataset_7$total_rec_late_fee) -->
<!-- ``` -->

```{r removing NAs columns}
# Removing columns that have > 0.05 NAs
dataset_7 <- dataset_7[, -which(colMeans(is.na(dataset_7)) > 0.05)]

```

```{r Data Preparation NAs removal}
# Given we want to do a regression analysis we want to change boolean string values to numeric ones.
# Omiting columns that only have NAs, ie. id and member_id.
dataset <- dataset_7[,colSums(is.na(dataset_7))<nrow(dataset_7)]
# 
# # changing the dataset as a tbl object.
# dataset <- as.tbl(dataset)
# # change NAs to 0 in integer columns
# dataset <- mutate_if(dataset, is.integer, ~replace(., is.na(.), 0))
# # change NAs to 0 in doubles columns
# 
# dataset <- mutate_if(dataset, is.numeric, ~replace(., is.na(.), 0))
# # change NAs to 0 in strings columns
# 
# dataset <- mutate_if(dataset, is.character, ~replace(., is.na(.), 0))
# 
# # calculating the number of unique levels per column
# sapply(dataset, function(col) length(unique(col)))

#removing dataset_7
rm(dataset_7)

# # attaching the cleaned dataset
# attach(dataset)

```

```{r removal of unwanted factors}
# we remove desc as it is descrbing the purpose of the loan given it's unstructured data we can't do much about it.
# Given we have a status column and date for all the factors that 
# emp_title has too many levels to be used 
# zip_code has too many levels and is a covariance of addr_state, thus we can remove it.

# Too keep: earliest_cr_line could be an interesting variable to dummy code, we could transform it to only hold the year and make it a numerical value. same is true for sec_app_earliest_cr_line

# last_pymnt_d and next_pymnt_d will be removed
# addr_state is remove as it's not significant
# grade is remove as it's a covariance of sub_grade
dataset <- subset(dataset, select = -c(desc, emp_title, issue_d, title, zip_code, last_pymnt_d, next_pymnt_d, last_credit_pull_d, hardship_end_date, hardship_start_date, payment_plan_start_date, debt_settlement_flag_date, settlement_date, addr_state, grade) )
```

```{r Dummy coding sub_grade}
# sub_grade has more than 32 levels which is a hard limit for random forest.
# We'll dummy code it to circument this
levels_sub_grade <- levels(dataset$sub_grade)
dataset$sub_grade<- as.numeric(mapvalues(dataset$sub_grade, levels_sub_grade, seq(from = 1, to = 35, by = 1)))
levels(dataset$sub_grade)
```

```{r Dummy coding emp_lenght}
# s
levels_emp_length <- levels(dataset$emp_length)
dataset$emp_length <- ordered(dataset$emp_length, levels = c("n/a", "< 1 year", "1 year", "2 years", "3 years","4 years", "5 years","6 years", "7 years", "8 years", "9 years", "10+ years"))
levels(dataset$emp_length)
dataset$emp_length <- as.numeric(mapvalues(dataset$emp_length, levels_emp_length, seq(from = -1, to = 10, by = 1)))
levels(dataset$emp_length)

```

<!-- ```{r} -->
<!-- # remove old emp_length, sub_grade -->
<!-- dataset <- subset(dataset, select = -c(emp_length, sub_grade) ) -->
<!-- ``` -->


<!-- ```{r Data Cleaning hardship_type} -->
<!-- # changing emp_title type -->
<!-- dataset$hardship_type <- as.character(dataset$hardship_type) -->
<!-- # Replacing empting values in hardship_type to '0' -->
<!-- dataset$hardship_type <- sub("No deferral", "0", dataset$hardship_type) -->
<!-- # Replacing '' values in hardship_type to '0' -->
<!-- dataset$hardship_type <- sub("INTEREST ONLY-3 MONTHS DEFERRAL", "1", dataset$hardship_type) -->
<!-- ``` -->

<!-- ```{r total_rec_late_fee} -->
<!-- levels(total_rec_late_fee) -->
<!-- ``` -->

```{r Dummy coding earliest_cr_line}
# grouping earliest_cr_line by year
dataset$earliest_cr_line <- as.integer(substring(dataset$earliest_cr_line, 5))
```

```{r Dummy coding sec_app_earliest_cr_line}
# grouping earliest_cr_line by year
dataset$sec_app_earliest_cr_line <- as.integer(substring(as.character(dataset$sec_app_earliest_cr_line), 5))
dataset$sec_app_earliest_cr_line[is.na(dataset$sec_app_earliest_cr_line)] <- 0
typeof(dataset$sec_app_earliest_cr_line)
levels(dataset$sec_app_earliest_cr_line)
```

```{r correlation matrix}

# correlation matrix by p-value
install.packages("Hmisc")
library("Hmisc")
corr.matrix<-rcorr(as.matrix(dataset), na.actions = na.omit)

# correlogram combined with significance test <- only correlations that are relevant are shown in the plot
install.packages("corrplot")
library(corrplot)
corrplot(corr.matrix, type="upper", order="hclust", 
         sig.level = 0.01, insig = "blank")

# still gives out na error<- how can we remove all nas to make it work?

```



