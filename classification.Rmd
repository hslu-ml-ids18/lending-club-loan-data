---
title: "Group 7 - Classification model for the default status"
author: "L. Becker, A. Chebatarova, A. Kandel, A.Kusche, R. Mizrak"
date: 'Sys.Date()'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

## Initialization

```{r initialization, message=FALSE, warning=FALSE, results="hide"}
source(file = "functions.R")
func_init_env()
```

```{r loading Rds file, results="hide"}
dataset <- func_data_load()
```

```{r preprocessing, echo=TRUE}
dataset <- func_data_prep(dataset)
```


```{r concluded loans}
# filter out all observations with loan_status == Current & check loan_status
setDT(dataset)
dataset <- dataset[loan_status != 'Current']
dataset$loan_status[dataset$loan_status != "Fully Paid"] <- "Default"

# Removes unused factor levels
dataset$loan_status <- factor(dataset$loan_status)

```

```{r validation set approach}
# setting a seed for reproducability
set.seed(7)

# random split into  train and test set, with a ratio of 20:80
trainIndex <- sample(1:nrow(dataset),0.01*nrow(dataset))

train.data <- dataset[trainIndex]
test.data  <- dataset[-trainIndex]

```

Use Principal Component Analysis for base transformation and then compare it with the Partial Least Squares Regression result. Select the best base with cross validation, using the better of the two approaches. 
```{r, message=FALSE, warning=FALSE, results="hide"}

#the selection of the principal components to incorporate in the model is not supervised by the outcome variable!
train.pca <- prcomp(subset(train.data, select = -c(term, home_ownership, verification_status, loan_status, pymnt_plan, purpose, initial_list_status, application_type, verification_status_joint, hardship_flag, hardship_type, hardship_reason, hardship_status, hardship_loan_status, disbursement_method, debt_settlement_flag, settlement_status) ), center = TRUE,scale. = TRUE)

summary(train.pca)

#make a biplot, which includes both the position of each sample in terms of PC1 and PC2
biplot(train.pca)

# Build the model on training set

model <- train(
  loan_status~., data = subset(train.data, select = -c(term, home_ownership, verification_status, pymnt_plan, purpose, initial_list_status, application_type, verification_status_joint, hardship_flag, hardship_type, hardship_reason, hardship_status, hardship_loan_status, disbursement_method, debt_settlement_flag, settlement_status) ), method = "pls",
  scale = TRUE,
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )



# Plot model RMSE vs different values of components
plot(model)
# Print the best tuning parameter ncomp that
# minimize the cross-validation error, RMSE
model$bestTune







```


Perform Partial Least Squares Regression
```{r}

```

Perform the classification using KNN, Logistic Regression, Decision tree and Random forest.
```{r }

```

Compare the respective train and test error performances to select one of these approaches.
```{r }

```

Perform the prediction on the validation set and compute the confusion matrix.
```{r }

```

Conceptually compare your approach with a solution existing for this problem. (Default
prediction is a very well-known problem in literature).
```{r }

```
